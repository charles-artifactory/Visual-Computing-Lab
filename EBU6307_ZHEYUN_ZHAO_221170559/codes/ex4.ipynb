{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cc31047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备: mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "INPUT_DIR = '../inputs/MiddleburyDataset/data/'\n",
    "OUTPUT_DIR = '../results'\n",
    "\n",
    "# 创建输出目录\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"使用设备: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72397ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_calib_file(calib_file):\n",
    "    \"\"\"读取校准文件并提取参数\"\"\"\n",
    "    with open(calib_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    params = {}\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#'):\n",
    "            continue\n",
    "        \n",
    "        key_value = line.split('=')\n",
    "        if len(key_value) != 2:\n",
    "            continue\n",
    "        \n",
    "        key, value = key_value\n",
    "        \n",
    "        # 处理相机矩阵\n",
    "        if key == 'cam0' or key == 'cam1':\n",
    "            # 示例格式: cam0=[1733.74 0 792.27; 0 1733.74 541.89; 0 0 1]\n",
    "            value = value.replace('[', '').replace(']', '')\n",
    "            matrix_values = []\n",
    "            for row in value.split(';'):\n",
    "                if row:\n",
    "                    row_values = [float(v) for v in row.split()]\n",
    "                    matrix_values.extend(row_values)\n",
    "            params[key] = matrix_values\n",
    "        # 处理其他数值参数\n",
    "        else:\n",
    "            try:\n",
    "                params[key] = float(value)\n",
    "            except ValueError:\n",
    "                params[key] = value\n",
    "    \n",
    "    # 确保基本参数存在，如果缺失则使用默认值\n",
    "    if 'width' not in params:\n",
    "        params['width'] = 1920\n",
    "    if 'height' not in params:\n",
    "        params['height'] = 1080\n",
    "    if 'ndisp' not in params:\n",
    "        params['ndisp'] = 192\n",
    "    \n",
    "    return params\n",
    "\n",
    "def read_pfm(file):\n",
    "    \"\"\"读取PFM文件\"\"\"\n",
    "    with open(file, 'rb') as f:\n",
    "        # Line 1: PF=>RGB (3 channels), Pf=>Greyscale (1 channel)\n",
    "        header = f.readline().decode('utf-8').rstrip()\n",
    "        if header == 'PF':\n",
    "            color = True\n",
    "        elif header == 'Pf':\n",
    "            color = False\n",
    "        else:\n",
    "            raise Exception('Not a PFM file: ' + file)\n",
    "        \n",
    "        # Line 2: dimensions\n",
    "        dim_match = re.match(r'^(\\d+)\\s(\\d+)\\s$', f.readline().decode('utf-8'))\n",
    "        if dim_match:\n",
    "            width, height = map(int, dim_match.groups())\n",
    "        else:\n",
    "            raise Exception('Malformed PFM header: ' + file)\n",
    "        \n",
    "        # Line 3: scale factor (negative for little-endian)\n",
    "        scale = float(f.readline().decode('utf-8').rstrip())\n",
    "        if scale < 0:  # little-endian\n",
    "            endian = '<'\n",
    "        else:\n",
    "            endian = '>'  # big-endian\n",
    "        \n",
    "        # Data\n",
    "        data = np.fromfile(f, endian + 'f')\n",
    "        shape = (height, width, 3) if color else (height, width)\n",
    "        data = np.reshape(data, shape)\n",
    "        data = np.flipud(data)  # Flip vertically\n",
    "        \n",
    "        return data, scale\n",
    "\n",
    "class MiddleburyDataset(Dataset):\n",
    "    def __init__(self, root_dir, scenes, transform=None, phase='train', target_size=(256, 512)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): 包含所有场景的目录\n",
    "            scenes (list): 要包含的场景名称列表\n",
    "            transform (callable, optional): 可选的要应用于样本的变换\n",
    "            phase (str): 'train' 或 'test'\n",
    "            target_size (tuple): 调整后的目标尺寸 (height, width)\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.scenes = scenes\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "        self.target_size = target_size\n",
    "        self.samples = []\n",
    "        \n",
    "        # 收集所有有效样本\n",
    "        for scene in scenes:\n",
    "            scene_dir = os.path.join(root_dir, scene)\n",
    "            \n",
    "            # 获取校准文件路径\n",
    "            calib_file = os.path.join(scene_dir, 'calib.txt')\n",
    "            \n",
    "            # 获取默认左右图像\n",
    "            left_img_path = os.path.join(scene_dir, 'im0.png')\n",
    "            right_img_path = os.path.join(scene_dir, 'im1.png')\n",
    "            left_disp_path = os.path.join(scene_dir, 'disp0.pfm')\n",
    "            \n",
    "            if os.path.exists(left_img_path) and os.path.exists(right_img_path) and os.path.exists(left_disp_path) and os.path.exists(calib_file):\n",
    "                # 读取校准信息\n",
    "                calib_params = read_calib_file(calib_file)\n",
    "                \n",
    "                self.samples.append({\n",
    "                    'left_img': left_img_path,\n",
    "                    'right_img': right_img_path,\n",
    "                    'left_disp': left_disp_path,\n",
    "                    'scene': scene,\n",
    "                    'calib_params': calib_params\n",
    "                })\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # 获取校准参数\n",
    "        calib_params = sample['calib_params']\n",
    "        original_width = int(calib_params['width'])\n",
    "        original_height = int(calib_params['height'])\n",
    "        max_disp = int(calib_params['ndisp'])\n",
    "        \n",
    "        # 加载图像\n",
    "        left_img = Image.open(sample['left_img']).convert('RGB')\n",
    "        right_img = Image.open(sample['right_img']).convert('RGB')\n",
    "        \n",
    "        # 应用变换到RGB图像\n",
    "        if self.transform:\n",
    "            left_img = self.transform(left_img)\n",
    "            right_img = self.transform(right_img)\n",
    "        \n",
    "        # 加载视差图\n",
    "        disparity, _ = read_pfm(sample['left_disp'])\n",
    "        disparity = disparity.astype(np.float32)\n",
    "        \n",
    "        # 调整视差图大小 - 使用双线性插值\n",
    "        disparity_pil = Image.fromarray(disparity)\n",
    "        disparity_pil = disparity_pil.resize(self.target_size, Image.BILINEAR)\n",
    "        disparity = np.array(disparity_pil)\n",
    "        \n",
    "        # 视差缩放因子 - 基于尺寸比例\n",
    "        width_scale = self.target_size[1] / original_width\n",
    "        disparity = disparity * width_scale\n",
    "        \n",
    "        # 转换视差为张量\n",
    "        disparity = torch.from_numpy(disparity)\n",
    "        \n",
    "        # 返回带有校准参数的样本\n",
    "        return {\n",
    "            'left': left_img,\n",
    "            'right': right_img,\n",
    "            'disparity': disparity,\n",
    "            'scene': sample['scene'],\n",
    "            'calib_params': calib_params,\n",
    "            'max_disp': max_disp\n",
    "        }\n",
    "\n",
    "def get_data_loaders(root_dir, fold_idx, k=5, batch_size=1):\n",
    "    \"\"\"\n",
    "    为k折交叉验证创建训练和验证数据加载器\n",
    "    \n",
    "    Args:\n",
    "        root_dir (str): 数据集路径\n",
    "        fold_idx (int): 当前折索引 (0 to k-1)\n",
    "        k (int): 折数\n",
    "        batch_size (int): 批大小\n",
    "    \n",
    "    Returns:\n",
    "        train_loader, val_loader, val_scenes, max_disp\n",
    "    \"\"\"\n",
    "    # 列出所有场景\n",
    "    scenes = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "    scenes.sort()  # 确保场景列表顺序一致\n",
    "    \n",
    "    print(f\"找到 {len(scenes)} 个场景: {scenes[:5]}...\")\n",
    "    \n",
    "    # 设置k折交叉验证\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    # 获取当前折的训练和验证索引\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    \n",
    "    for i, (train_idx, val_idx) in enumerate(kf.split(scenes)):\n",
    "        if i == fold_idx:\n",
    "            train_indices = train_idx\n",
    "            val_indices = val_idx\n",
    "            break\n",
    "    \n",
    "    train_scenes = [scenes[i] for i in train_indices]\n",
    "    val_scenes = [scenes[i] for i in val_indices]\n",
    "    \n",
    "    print(f\"Fold {fold_idx+1}: 训练场景数: {len(train_scenes)}, 验证场景数: {len(val_scenes)}\")\n",
    "    \n",
    "    # 定义变换 - 明确指定目标尺寸\n",
    "    target_size = (256, 512)\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(target_size),  # 调整大小为(256, 512)\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # 创建数据集\n",
    "    train_dataset = MiddleburyDataset(root_dir, train_scenes, transform=transform, phase='train', target_size=target_size)\n",
    "    val_dataset = MiddleburyDataset(root_dir, val_scenes, transform=transform, phase='test', target_size=target_size)\n",
    "    \n",
    "    print(f\"训练数据集大小: {len(train_dataset)}, 验证数据集大小: {len(val_dataset)}\")\n",
    "    \n",
    "    # 查看第一个场景的校准信息\n",
    "    if len(train_dataset) > 0:\n",
    "        sample = train_dataset[0]\n",
    "        calib_params = sample['calib_params']\n",
    "        print(f\"场景 '{sample['scene']}' 校准信息:\")\n",
    "        print(f\"  原始尺寸: {int(calib_params['width'])}x{int(calib_params['height'])}\")\n",
    "        print(f\"  最大视差: {int(calib_params['ndisp'])}\")\n",
    "        print(f\"  视差范围: {calib_params.get('vmin', 'N/A')} - {calib_params.get('vmax', 'N/A')}\")\n",
    "        print(f\"  基线长度: {calib_params.get('baseline', 'N/A')} mm\")\n",
    "        \n",
    "        # 确定最大视差值\n",
    "        max_disp = int(calib_params['ndisp'])\n",
    "    else:\n",
    "        max_disp = 192  # 默认值\n",
    "    \n",
    "    # 创建数据加载器 - 使用num_workers=0避免多进程问题\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    return train_loader, val_loader, val_scenes, max_disp\n",
    "\n",
    "# 测试数据加载\n",
    "def explore_dataset(data_dir):\n",
    "    \"\"\"探索数据集并可视化几个样本\"\"\"\n",
    "    scenes = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
    "    scenes.sort()\n",
    "    \n",
    "    print(f\"找到 {len(scenes)} 个场景\")\n",
    "    \n",
    "    # 随机选择3个场景进行可视化\n",
    "    sample_scenes = random.sample(scenes, min(3, len(scenes)))\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, scene in enumerate(sample_scenes):\n",
    "        scene_dir = os.path.join(data_dir, scene)\n",
    "        \n",
    "        # 加载左右图像\n",
    "        left_img = Image.open(os.path.join(scene_dir, 'im0.png'))\n",
    "        right_img = Image.open(os.path.join(scene_dir, 'im1.png'))\n",
    "        \n",
    "        # 加载视差图\n",
    "        disparity, _ = read_pfm(os.path.join(scene_dir, 'disp0.pfm'))\n",
    "        \n",
    "        # 将视差图转换为可视化图像\n",
    "        disparity_normalized = disparity / np.max(disparity)\n",
    "        \n",
    "        # 绘制图像\n",
    "        plt.subplot(3, 3, i*3+1)\n",
    "        plt.imshow(left_img)\n",
    "        plt.title(f'{scene} - Left Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, 3, i*3+2)\n",
    "        plt.imshow(right_img)\n",
    "        plt.title(f'{scene} - Right Image')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(3, 3, i*3+3)\n",
    "        plt.imshow(disparity_normalized, cmap='plasma')\n",
    "        plt.title(f'{scene} - Disparity Map')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, 'dataset_samples.png'))\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"数据集样本已保存至 {os.path.join(OUTPUT_DIR, 'dataset_samples.png')}\")\n",
    "\n",
    "# 可视化一个批次\n",
    "def visualize_batch(batch, output_dir, prefix=\"batch\"):\n",
    "    \"\"\"可视化批次中的样本\"\"\"\n",
    "    # 处理批次的第一个样本\n",
    "    i = 0\n",
    "    left_img = batch['left'][i].permute(1, 2, 0).cpu().numpy()\n",
    "    right_img = batch['right'][i].permute(1, 2, 0).cpu().numpy()\n",
    "    disp_img = batch['disparity'][i].cpu().numpy()\n",
    "    scene_name = batch['scene'][i]\n",
    "    \n",
    "    # 反归一化图像\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    left_img = left_img * std + mean\n",
    "    right_img = right_img * std + mean\n",
    "    \n",
    "    # 裁剪到[0,1]\n",
    "    left_img = np.clip(left_img, 0, 1)\n",
    "    right_img = np.clip(right_img, 0, 1)\n",
    "    \n",
    "    # 归一化视差图\n",
    "    disp_min = disp_img.min()\n",
    "    disp_max = disp_img.max()\n",
    "    if disp_max > disp_min:\n",
    "        disp_normalized = (disp_img - disp_min) / (disp_max - disp_min)\n",
    "    else:\n",
    "        disp_normalized = disp_img\n",
    "    \n",
    "    # 创建图像\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(left_img)\n",
    "    plt.title(f'Left Image - {scene_name}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(right_img)\n",
    "    plt.title(f'Right Image - {scene_name}')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(disp_normalized, cmap='plasma')\n",
    "    plt.title(f'Disparity Map - {scene_name}')\n",
    "    plt.colorbar(label='Normalized Disparity')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'{prefix}_{scene_name}.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"已保存样本图像: {os.path.join(output_dir, f'{prefix}_{scene_name}.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f7bf73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class FeatureExtraction(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtraction, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        \n",
    "        # 第一个卷积层\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        # ResNet块\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, 3)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, 6, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, 3, stride=2)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x1 = self.layer1(x)\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "        \n",
    "        return x4\n",
    "\n",
    "class CostVolume(nn.Module):\n",
    "    def __init__(self, max_disp=192):\n",
    "        super(CostVolume, self).__init__()\n",
    "        self.max_disp = max_disp\n",
    "        \n",
    "    def forward(self, left_feature, right_feature):\n",
    "        B, C, H, W = left_feature.size()\n",
    "        cost_volume = torch.zeros(B, C*2, self.max_disp//4, H, W, device=left_feature.device)\n",
    "        \n",
    "        for i in range(self.max_disp//4):\n",
    "            if i > 0:\n",
    "                cost_volume[:, :C, i, :, i:] = left_feature[:, :, :, i:]\n",
    "                cost_volume[:, C:, i, :, i:] = right_feature[:, :, :, :-i]\n",
    "            else:\n",
    "                cost_volume[:, :C, i, :, :] = left_feature\n",
    "                cost_volume[:, C:, i, :, :] = right_feature\n",
    "                \n",
    "        cost_volume = cost_volume.contiguous()\n",
    "        return cost_volume\n",
    "\n",
    "class CostAggregation(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(CostAggregation, self).__init__()\n",
    "        \n",
    "        self.conv3d_1 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv3d_2 = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv3d_3 = nn.Sequential(\n",
    "            nn.Conv3d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv3d_4 = nn.Sequential(\n",
    "            nn.Conv3d(64, 1, kernel_size=3, padding=1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv3d_1(x)\n",
    "        x = self.conv3d_2(x)\n",
    "        x = self.conv3d_3(x)\n",
    "        x = self.conv3d_4(x)\n",
    "        return x\n",
    "\n",
    "class DisparityRegression(nn.Module):\n",
    "    def __init__(self, max_disp):\n",
    "        super(DisparityRegression, self).__init__()\n",
    "        self.max_disp = max_disp\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, _, D, H, W = x.size()\n",
    "        x = F.softmax(x.squeeze(1), dim=1)\n",
    "        \n",
    "        # 创建视差值 [0, 1, 2, ..., max_disp-1]\n",
    "        disp_values = torch.arange(0, self.max_disp//4, dtype=torch.float32, device=x.device)\n",
    "        disp_values = disp_values.view(1, D, 1, 1)\n",
    "        \n",
    "        # 计算期望的视差值\n",
    "        disparity = torch.sum(x * disp_values, dim=1)\n",
    "        \n",
    "        # 缩放到全分辨率\n",
    "        disparity = disparity * 4\n",
    "        \n",
    "        return disparity\n",
    "\n",
    "class StereoNet(nn.Module):\n",
    "    def __init__(self, max_disp=192):\n",
    "        super(StereoNet, self).__init__()\n",
    "        self.max_disp = max_disp\n",
    "        \n",
    "        # 特征提取\n",
    "        self.feature_extraction = FeatureExtraction()\n",
    "        \n",
    "        # 成本体积构建\n",
    "        self.cost_volume = CostVolume(max_disp)\n",
    "        \n",
    "        # 成本体积聚合\n",
    "        self.cost_aggregation = CostAggregation(512*2)\n",
    "        \n",
    "        # 视差回归\n",
    "        self.disparity_regression = DisparityRegression(max_disp)\n",
    "        \n",
    "    def forward(self, left, right):\n",
    "        # 提取特征\n",
    "        left_feature = self.feature_extraction(left)\n",
    "        right_feature = self.feature_extraction(right)\n",
    "        \n",
    "        # 构建成本体积\n",
    "        cost_volume = self.cost_volume(left_feature, right_feature)\n",
    "        \n",
    "        # 聚合成本\n",
    "        cost = self.cost_aggregation(cost_volume)\n",
    "        \n",
    "        # 回归\n",
    "        disparity = self.disparity_regression(cost)\n",
    "        \n",
    "        # 上采样到原始大小\n",
    "        disparity = F.interpolate(disparity.unsqueeze(1), size=(left.size(2), left.size(3)), \n",
    "                                 mode='bilinear', align_corners=False).squeeze(1)\n",
    "        \n",
    "        return disparity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a5da1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, fold_idx, max_disp=192, num_epochs=20):\n",
    "    \"\"\"训练立体模型\"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    # 损失函数\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    \n",
    "    # 优化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # 学习率调度器\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "    \n",
    "    # 训练循环\n",
    "    best_val_loss = float('inf')\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_disparities = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for sample in tqdm(train_loader, desc=f'Fold {fold_idx+1}, Epoch {epoch+1}/{num_epochs} (Training)'):\n",
    "            left = sample['left'].to(device)\n",
    "            right = sample['right'].to(device)\n",
    "            target_disp = sample['disparity'].to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            optimizer.zero_grad()\n",
    "            output_disp = model(left, right)\n",
    "            \n",
    "            # 确保形状匹配 - 如果需要，调整目标视差图大小\n",
    "            if output_disp.shape[1:] != target_disp.shape[1:]:\n",
    "                target_disp = F.interpolate(target_disp.unsqueeze(1), \n",
    "                                           size=output_disp.shape[1:], \n",
    "                                           mode='bilinear',\n",
    "                                           align_corners=False).squeeze(1)\n",
    "            \n",
    "            # 创建有效视差的掩码 - 使用每个样本的最大视差值\n",
    "            batch_max_disp = max_disp\n",
    "            mask = (target_disp > 0) & (target_disp < batch_max_disp)\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(output_disp[mask], target_disp[mask])\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        \n",
    "        # 验证\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_disp_errors = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for sample in tqdm(val_loader, desc=f'Fold {fold_idx+1}, Epoch {epoch+1}/{num_epochs} (Validation)'):\n",
    "                left = sample['left'].to(device)\n",
    "                right = sample['right'].to(device)\n",
    "                target_disp = sample['disparity'].to(device)\n",
    "                \n",
    "                # 前向传播\n",
    "                output_disp = model(left, right)\n",
    "                \n",
    "                # 确保形状匹配 - 如果需要，调整目标视差图大小\n",
    "                if output_disp.shape[1:] != target_disp.shape[1:]:\n",
    "                    target_disp = F.interpolate(target_disp.unsqueeze(1), \n",
    "                                               size=output_disp.shape[1:], \n",
    "                                               mode='bilinear',\n",
    "                                               align_corners=False).squeeze(1)\n",
    "                \n",
    "                # 创建有效视差的掩码\n",
    "                batch_max_disp = max_disp\n",
    "                mask = (target_disp > 0) & (target_disp < batch_max_disp)\n",
    "                \n",
    "                # 计算损失\n",
    "                loss = criterion(output_disp[mask], target_disp[mask])\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # 计算视差误差\n",
    "                disp_error = torch.abs(output_disp[mask] - target_disp[mask]).mean().item()\n",
    "                val_disp_errors.append(disp_error)\n",
    "                \n",
    "                # 保存最后一个epoch的预测视差\n",
    "                if epoch == num_epochs - 1:\n",
    "                    for i in range(output_disp.size(0)):\n",
    "                        # 保存校准参数以便后续转换为深度\n",
    "                        calib_params = {k: v for k, v in sample['calib_params'].items()}\n",
    "                        \n",
    "                        val_disparities.append({\n",
    "                            'scene': sample['scene'][i],\n",
    "                            'disparity': output_disp[i].cpu().numpy(),\n",
    "                            'target': target_disp[i].cpu().numpy(),\n",
    "                            'calib_params': calib_params\n",
    "                        })\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_disp_error = np.mean(val_disp_errors)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(f'Fold {fold_idx+1}, Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {avg_train_loss:.4f}')\n",
    "        print(f'  Val Loss: {avg_val_loss:.4f}')\n",
    "        print(f'  Val Disparity Error: {avg_disp_error:.4f} pixels')\n",
    "        \n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 如果验证损失改善则保存模型\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, f'best_model_fold{fold_idx+1}.pth'))\n",
    "    \n",
    "    return val_disparities, avg_disp_error\n",
    "\n",
    "def run_cross_validation(data_root, output_dir, k=5, num_epochs=20):\n",
    "    \"\"\"运行k折交叉验证\"\"\"\n",
    "    # 创建输出目录\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 结果\n",
    "    all_val_disparities = []\n",
    "    fold_errors = []\n",
    "    test_scenes = []\n",
    "    \n",
    "    # 运行k折交叉验证\n",
    "    for fold_idx in range(k):\n",
    "        print(f\"Starting fold {fold_idx+1}/{k}\")\n",
    "        \n",
    "        # 获取当前折的数据加载器\n",
    "        train_loader, val_loader, val_scenes, max_disp = get_data_loaders(data_root, fold_idx, k=k)\n",
    "        test_scenes.append(val_scenes)\n",
    "        \n",
    "        print(f\"使用最大视差值: {max_disp}\")\n",
    "        \n",
    "        # 初始化模型\n",
    "        model = StereoNet(max_disp=max_disp)\n",
    "        \n",
    "        # 训练模型\n",
    "        val_disparities, fold_error = train_model(model, train_loader, val_loader, fold_idx, max_disp, num_epochs)\n",
    "        all_val_disparities.extend(val_disparities)\n",
    "        fold_errors.append(fold_error)\n",
    "        \n",
    "        print(f\"Fold {fold_idx+1} completed. Disparity Error: {fold_error:.4f} pixels\")\n",
    "    \n",
    "    # 保存交叉验证结果\n",
    "    cv_results = pd.DataFrame({\n",
    "        'Fold': range(1, k+1),\n",
    "        'Test_Scenes': [str(scenes) for scenes in test_scenes],\n",
    "        'Disparity_Error': fold_errors\n",
    "    })\n",
    "    cv_results.to_csv(os.path.join(output_dir, 'ex4c_crossvalidation.csv'), index=False)\n",
    "    \n",
    "    # 生成样本视差图和深度图（前3个示例）\n",
    "    for i, disp_data in enumerate(all_val_disparities[:3]):\n",
    "        scene = disp_data['scene']\n",
    "        pred_disp = disp_data['disparity']\n",
    "        calib_params = disp_data['calib_params']\n",
    "        \n",
    "        # 获取相机参数\n",
    "        baseline = float(calib_params.get('baseline', 100.0))\n",
    "        focal_length = float(calib_params['cam0'][0])  # 焦距f在相机矩阵的[0,0]位置\n",
    "        doffs = float(calib_params.get('doffs', 0.0))\n",
    "        \n",
    "        # 计算深度 Z = (baseline * f) / (d + doffs)\n",
    "        # 避免除以零\n",
    "        valid_disparity = np.where(pred_disp > 0.1, pred_disp, 0.1)\n",
    "        depth = (baseline * focal_length) / (valid_disparity + doffs)\n",
    "        \n",
    "        # 归一化视差和深度以便可视化\n",
    "        norm_disp = pred_disp / np.max(pred_disp)\n",
    "        \n",
    "        # 限制深度范围以便可视化（忽略极端值）\n",
    "        depth_cap = np.percentile(depth, 95)  # 使用95百分位数作为上限\n",
    "        depth_vis = np.clip(depth, 0, depth_cap)\n",
    "        norm_depth = depth_vis / np.max(depth_vis)\n",
    "        \n",
    "        # 保存视差图\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(norm_disp, cmap='plasma')\n",
    "        plt.colorbar(label='Normalized Disparity')\n",
    "        plt.title(f'Predicted Disparity Map - Scene: {scene}')\n",
    "        plt.savefig(os.path.join(output_dir, f'ex4b_{scene}_disparitymap.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        # 保存深度图\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.imshow(norm_depth, cmap='viridis')\n",
    "        plt.colorbar(label='Normalized Depth (mm)')\n",
    "        plt.title(f'Predicted Depth Map - Scene: {scene}')\n",
    "        plt.savefig(os.path.join(output_dir, f'ex4b_{scene}_depthmap.png'))\n",
    "        plt.close()\n",
    "    \n",
    "    print(\"Cross-validation completed. Results saved to\", output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dffa3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_disparity_and_depth(disparity, calib_params, scene_name, output_dir):\n",
    "    \"\"\"\n",
    "    将视差图转换为深度图并可视化\n",
    "    \n",
    "    Args:\n",
    "        disparity: 视差图\n",
    "        calib_params: 校准参数\n",
    "        scene_name: 场景名称\n",
    "        output_dir: 输出目录\n",
    "    \"\"\"\n",
    "    # 获取相机参数\n",
    "    baseline = float(calib_params.get('baseline', 100.0))\n",
    "    focal_length = float(calib_params['cam0'][0])  # 焦距f在相机矩阵的[0,0]位置\n",
    "    doffs = float(calib_params.get('doffs', 0.0))\n",
    "    \n",
    "    # 计算深度 Z = (baseline * f) / (d + doffs)\n",
    "    # 避免除以零\n",
    "    valid_disparity = np.where(disparity > 0.1, disparity, 0.1)\n",
    "    depth = (baseline * focal_length) / (valid_disparity + doffs)\n",
    "    \n",
    "    # 创建图像\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # 视差图\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(disparity, cmap='plasma')\n",
    "    plt.colorbar(label='Disparity (pixels)')\n",
    "    plt.title(f'Disparity Map - {scene_name}')\n",
    "    \n",
    "    # 深度图\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # 限制深度范围以便可视化\n",
    "    depth_cap = np.percentile(depth, 95)  # 使用95百分位数作为上限\n",
    "    depth_vis = np.clip(depth, 0, depth_cap)\n",
    "    plt.imshow(depth_vis, cmap='viridis')\n",
    "    plt.colorbar(label='Depth (mm)')\n",
    "    plt.title(f'Depth Map - {scene_name}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, f'{scene_name}_disparity_depth.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"已保存{scene_name}的视差图和深度图\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d4cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box(draw, x, y, width, height, text, color):\n",
    "    \"\"\"绘制带文本的框\"\"\"\n",
    "    # 转换颜色名称为RGB\n",
    "    color_dict = {\n",
    "        \"lightblue\": (173, 216, 230),\n",
    "        \"lightgreen\": (144, 238, 144),\n",
    "        \"orange\": (255, 165, 0),\n",
    "        \"lightsalmon\": (255, 160, 122),\n",
    "        \"lightpink\": (255, 182, 193),\n",
    "        \"gold\": (255, 215, 0)\n",
    "    }\n",
    "    rgb_color = color_dict.get(color, (200, 200, 200))\n",
    "    \n",
    "    # 绘制矩形\n",
    "    draw.rectangle([x, y, x+width, y+height], fill=rgb_color, outline=(0, 0, 0))\n",
    "    \n",
    "    # 绘制文本\n",
    "    lines = text.split('\\n')\n",
    "    font = ImageFont.load_default()\n",
    "    line_height = height // (len(lines) + 1)\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        text_width = len(line) * 6  # 近似文本宽度\n",
    "        text_x = x + (width - text_width) // 2\n",
    "        text_y = y + (i + 1) * line_height\n",
    "        draw.text((text_x, text_y), line, fill=(0, 0, 0))\n",
    "\n",
    "def draw_arrow(draw, x1, y1, x2, y2):\n",
    "    \"\"\"绘制从(x1, y1)到(x2, y2)的箭头\"\"\"\n",
    "    draw.line([x1, y1, x2, y2], fill=(0, 0, 0), width=2)\n",
    "    \n",
    "    # 绘制箭头头部\n",
    "    angle = np.arctan2(y2 - y1, x2 - x1)\n",
    "    arrow_length = 10\n",
    "    arrow_width = 5\n",
    "    \n",
    "    x_end = x2\n",
    "    y_end = y2\n",
    "    \n",
    "    # 计算箭头头部的点\n",
    "    x_arrow1 = x_end - arrow_length * np.cos(angle) + arrow_width * np.sin(angle)\n",
    "    y_arrow1 = y_end - arrow_length * np.sin(angle) - arrow_width * np.cos(angle)\n",
    "    \n",
    "    x_arrow2 = x_end - arrow_length * np.cos(angle) - arrow_width * np.sin(angle)\n",
    "    y_arrow2 = y_end - arrow_length * np.sin(angle) + arrow_width * np.cos(angle)\n",
    "    \n",
    "    # 绘制箭头头部\n",
    "    draw.polygon([(x_end, y_end), (x_arrow1, y_arrow1), (x_arrow2, y_arrow2)], fill=(0, 0, 0))\n",
    "\n",
    "def create_architecture_diagram(output_path=os.path.join(OUTPUT_DIR, 'ex4a_architecture.png')):\n",
    "    \"\"\"创建PSMNet架构的可视化\"\"\"\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    \n",
    "    # 创建一个大的空白图像\n",
    "    img_width = 1200\n",
    "    img_height = 800\n",
    "    img = Image.new('RGB', (img_width, img_height), color=(255, 255, 255))\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # 定义框的尺寸和位置\n",
    "    box_width = 160\n",
    "    box_height = 80\n",
    "    \n",
    "    # 绘制架构组件\n",
    "    \n",
    "    # 输入图像\n",
    "    draw_box(draw, 100, 100, box_width, box_height, \"Left Image\\n(Input)\", \"lightblue\")\n",
    "    draw_box(draw, 100, 250, box_width, box_height, \"Right Image\\n(Input)\", \"lightblue\")\n",
    "    \n",
    "    # 特征提取（共享权重）\n",
    "    draw_box(draw, 350, 100, box_width, box_height, \"Feature\\nExtraction\\n(ResNet)\", \"lightgreen\")\n",
    "    draw_box(draw, 350, 250, box_width, box_height, \"Feature\\nExtraction\\n(Shared weights)\", \"lightgreen\")\n",
    "    \n",
    "    # 绘制连接输入到特征提取的箭头\n",
    "    draw_arrow(draw, 100+box_width, 100+box_height//2, 350, 100+box_height//2)\n",
    "    draw_arrow(draw, 100+box_width, 250+box_height//2, 350, 250+box_height//2)\n",
    "    \n",
    "    # 成本体积\n",
    "    draw_box(draw, 600, 175, box_width, box_height, \"Cost Volume\\nConstruction\", \"orange\")\n",
    "    \n",
    "    # 绘制连接特征提取到成本体积的箭头\n",
    "    draw_arrow(draw, 350+box_width, 100+box_height//2, 600, 175+box_height//2)\n",
    "    draw_arrow(draw, 350+box_width, 250+box_height//2, 600, 175+box_height//2)\n",
    "    \n",
    "    # 3D CNN用于成本聚合\n",
    "    draw_box(draw, 850, 175, box_width, box_height, \"3D CNN\\nCost Aggregation\", \"lightsalmon\")\n",
    "    \n",
    "    # 绘制连接成本体积到成本聚合的箭头\n",
    "    draw_arrow(draw, 600+box_width, 175+box_height//2, 850, 175+box_height//2)\n",
    "    \n",
    "    # 视差回归\n",
    "    draw_box(draw, 850, 350, box_width, box_height, \"Disparity\\nRegression\", \"lightpink\")\n",
    "    \n",
    "    # 绘制连接成本聚合到视差回归的箭头\n",
    "    draw_arrow(draw, 850+box_width//2, 175+box_height, 850+box_width//2, 350)\n",
    "    \n",
    "    # 输出视差图\n",
    "    draw_box(draw, 600, 500, box_width, box_height, \"Disparity Map\\n(Output)\", \"gold\")\n",
    "    \n",
    "    # 绘制连接视差回归到输出的箭头\n",
    "    draw_arrow(draw, 850+box_width//2, 350+box_height, 850+box_width//2, 500+box_height//2)\n",
    "    draw_arrow(draw, 850+box_width//2, 500+box_height//2, 600+box_width, 500+box_height//2)\n",
    "    \n",
    "    # 标题和图例\n",
    "    font = ImageFont.load_default()\n",
    "    draw.text((450, 30), \"PSMNet Architecture for Stereo Depth Estimation\", fill=(0, 0, 0))\n",
    "    \n",
    "    # 保存图表\n",
    "    img.save(output_path)\n",
    "    print(f\"Architecture diagram saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f70880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture diagram saved to ../results/ex4a_architecture.png\n",
      "\n",
      "读取样本校准文件: ../inputs/MiddleburyDataset/data/artroom2/calib.txt\n",
      "校准参数:\n",
      "  cam0: [1734.04, 0.0, -133.21, 0.0, 1734.04, 542.27, 0.0, 0.0, 1.0]\n",
      "  cam1: [1734.04, 0.0, -133.21, 0.0, 1734.04, 542.27, 0.0, 0.0, 1.0]\n",
      "  doffs: 0.0\n",
      "  baseline: 529.5\n",
      "  width: 1920.0\n",
      "  height: 1080.0\n",
      "  ndisp: 190.0\n",
      "  vmin: 55.0\n",
      "  vmax: 160.0\n",
      "Starting fold 1/5\n",
      "找到 24 个场景: ['artroom1', 'artroom2', 'bandsaw1', 'bandsaw2', 'chess1']...\n",
      "Fold 1: 训练场景数: 19, 验证场景数: 5\n",
      "训练数据集大小: 19, 验证数据集大小: 5\n",
      "场景 'artroom2' 校准信息:\n",
      "  原始尺寸: 1920x1080\n",
      "  最大视差: 190\n",
      "  视差范围: 55.0 - 160.0\n",
      "  基线长度: 529.5 mm\n",
      "使用最大视差值: 190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1/20 (Training): 100%|██████████| 19/19 [00:04<00:00,  4.59it/s]\n",
      "Fold 1, Epoch 1/20 (Validation): 100%|██████████| 5/5 [00:01<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1/20:\n",
      "  Train Loss: 17.3057\n",
      "  Val Loss: 11.3477\n",
      "  Val Disparity Error: 11.8397 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 2/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.26it/s]\n",
      "Fold 1, Epoch 2/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 2/20:\n",
      "  Train Loss: 13.1012\n",
      "  Val Loss: 8.5108\n",
      "  Val Disparity Error: 9.0006 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 3/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.27it/s]\n",
      "Fold 1, Epoch 3/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 3/20:\n",
      "  Train Loss: 12.7881\n",
      "  Val Loss: 9.2359\n",
      "  Val Disparity Error: 9.7312 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 4/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.14it/s]\n",
      "Fold 1, Epoch 4/20 (Validation): 100%|██████████| 5/5 [00:00<00:00,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 4/20:\n",
      "  Train Loss: 12.5134\n",
      "  Val Loss: 8.3748\n",
      "  Val Disparity Error: 8.8647 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 5/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.03it/s]\n",
      "Fold 1, Epoch 5/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 5/20:\n",
      "  Train Loss: 12.5716\n",
      "  Val Loss: 8.0378\n",
      "  Val Disparity Error: 8.5288 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 6/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.17it/s]\n",
      "Fold 1, Epoch 6/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 6/20:\n",
      "  Train Loss: 11.6505\n",
      "  Val Loss: 8.9236\n",
      "  Val Disparity Error: 9.4168 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 7/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.16it/s]\n",
      "Fold 1, Epoch 7/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 7/20:\n",
      "  Train Loss: 11.0780\n",
      "  Val Loss: 10.5211\n",
      "  Val Disparity Error: 11.0107 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 8/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.10it/s]\n",
      "Fold 1, Epoch 8/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 8/20:\n",
      "  Train Loss: 11.9948\n",
      "  Val Loss: 9.0044\n",
      "  Val Disparity Error: 9.4981 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 9/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.22it/s]\n",
      "Fold 1, Epoch 9/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 9/20:\n",
      "  Train Loss: 12.0899\n",
      "  Val Loss: 8.4289\n",
      "  Val Disparity Error: 8.9191 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 10/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.12it/s]\n",
      "Fold 1, Epoch 10/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 10/20:\n",
      "  Train Loss: 11.3158\n",
      "  Val Loss: 9.5850\n",
      "  Val Disparity Error: 10.0729 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 11/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.15it/s]\n",
      "Fold 1, Epoch 11/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 11/20:\n",
      "  Train Loss: 11.3821\n",
      "  Val Loss: 8.0357\n",
      "  Val Disparity Error: 8.5235 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 12/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.18it/s]\n",
      "Fold 1, Epoch 12/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 12/20:\n",
      "  Train Loss: 10.0786\n",
      "  Val Loss: 8.2000\n",
      "  Val Disparity Error: 8.6876 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 13/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.17it/s]\n",
      "Fold 1, Epoch 13/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 13/20:\n",
      "  Train Loss: 9.4635\n",
      "  Val Loss: 7.5265\n",
      "  Val Disparity Error: 8.0137 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 14/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.09it/s]\n",
      "Fold 1, Epoch 14/20 (Validation): 100%|██████████| 5/5 [00:00<00:00,  9.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 14/20:\n",
      "  Train Loss: 8.0124\n",
      "  Val Loss: 6.6191\n",
      "  Val Disparity Error: 7.1053 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 15/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.07it/s]\n",
      "Fold 1, Epoch 15/20 (Validation): 100%|██████████| 5/5 [00:00<00:00,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 15/20:\n",
      "  Train Loss: 7.8412\n",
      "  Val Loss: 8.0485\n",
      "  Val Disparity Error: 8.5404 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 16/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.15it/s]\n",
      "Fold 1, Epoch 16/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 16/20:\n",
      "  Train Loss: 8.5490\n",
      "  Val Loss: 9.0581\n",
      "  Val Disparity Error: 9.5516 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 17/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.22it/s]\n",
      "Fold 1, Epoch 17/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 17/20:\n",
      "  Train Loss: 9.4665\n",
      "  Val Loss: 8.4130\n",
      "  Val Disparity Error: 8.9005 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 18/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.26it/s]\n",
      "Fold 1, Epoch 18/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 18/20:\n",
      "  Train Loss: 8.2634\n",
      "  Val Loss: 6.6658\n",
      "  Val Disparity Error: 7.1581 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 19/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.19it/s]\n",
      "Fold 1, Epoch 19/20 (Validation): 100%|██████████| 5/5 [00:00<00:00,  9.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 19/20:\n",
      "  Train Loss: 7.3038\n",
      "  Val Loss: 6.7941\n",
      "  Val Disparity Error: 7.2851 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 20/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.22it/s]\n",
      "Fold 1, Epoch 20/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 20/20:\n",
      "  Train Loss: 6.7601\n",
      "  Val Loss: 7.3217\n",
      "  Val Disparity Error: 7.8112 pixels\n",
      "Fold 1 completed. Disparity Error: 7.8112 pixels\n",
      "Starting fold 2/5\n",
      "找到 24 个场景: ['artroom1', 'artroom2', 'bandsaw1', 'bandsaw2', 'chess1']...\n",
      "Fold 2: 训练场景数: 19, 验证场景数: 5\n",
      "训练数据集大小: 19, 验证数据集大小: 5\n",
      "场景 'artroom1' 校准信息:\n",
      "  原始尺寸: 1920x1080\n",
      "  最大视差: 170\n",
      "  视差范围: 55.0 - 142.0\n",
      "  基线长度: 536.62 mm\n",
      "使用最大视差值: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.05it/s]\n",
      "Fold 2, Epoch 1/20 (Validation): 100%|██████████| 5/5 [00:00<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 1/20:\n",
      "  Train Loss: 16.9144\n",
      "  Val Loss: 10.6375\n",
      "  Val Disparity Error: 11.1286 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 2/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.49it/s]\n",
      "Fold 2, Epoch 2/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 2/20:\n",
      "  Train Loss: 13.3454\n",
      "  Val Loss: 12.1819\n",
      "  Val Disparity Error: 12.6689 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 3/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.54it/s]\n",
      "Fold 2, Epoch 3/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 3/20:\n",
      "  Train Loss: 12.6589\n",
      "  Val Loss: 10.9198\n",
      "  Val Disparity Error: 11.4128 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 4/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.51it/s]\n",
      "Fold 2, Epoch 4/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 4/20:\n",
      "  Train Loss: 11.6762\n",
      "  Val Loss: 10.1215\n",
      "  Val Disparity Error: 10.6100 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 5/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.46it/s]\n",
      "Fold 2, Epoch 5/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 5/20:\n",
      "  Train Loss: 11.3148\n",
      "  Val Loss: 9.6246\n",
      "  Val Disparity Error: 10.1119 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 6/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.64it/s]\n",
      "Fold 2, Epoch 6/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 6/20:\n",
      "  Train Loss: 12.3896\n",
      "  Val Loss: 10.4182\n",
      "  Val Disparity Error: 10.9104 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 7/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.62it/s]\n",
      "Fold 2, Epoch 7/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 7/20:\n",
      "  Train Loss: 11.7484\n",
      "  Val Loss: 10.8746\n",
      "  Val Disparity Error: 11.3630 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 8/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.63it/s]\n",
      "Fold 2, Epoch 8/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 8/20:\n",
      "  Train Loss: 11.5083\n",
      "  Val Loss: 10.7072\n",
      "  Val Disparity Error: 11.1967 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 9/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.60it/s]\n",
      "Fold 2, Epoch 9/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 9/20:\n",
      "  Train Loss: 11.5307\n",
      "  Val Loss: 10.6971\n",
      "  Val Disparity Error: 11.1858 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 10/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.63it/s]\n",
      "Fold 2, Epoch 10/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 10/20:\n",
      "  Train Loss: 11.4231\n",
      "  Val Loss: 9.9808\n",
      "  Val Disparity Error: 10.4741 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 11/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.58it/s]\n",
      "Fold 2, Epoch 11/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 11/20:\n",
      "  Train Loss: 10.7949\n",
      "  Val Loss: 10.0601\n",
      "  Val Disparity Error: 10.5510 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 12/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.54it/s]\n",
      "Fold 2, Epoch 12/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 12/20:\n",
      "  Train Loss: 9.6850\n",
      "  Val Loss: 9.7881\n",
      "  Val Disparity Error: 10.2805 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 13/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.54it/s]\n",
      "Fold 2, Epoch 13/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 13/20:\n",
      "  Train Loss: 8.8456\n",
      "  Val Loss: 10.4396\n",
      "  Val Disparity Error: 10.9316 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 14/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.54it/s]\n",
      "Fold 2, Epoch 14/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 14/20:\n",
      "  Train Loss: 8.4043\n",
      "  Val Loss: 9.8653\n",
      "  Val Disparity Error: 10.3575 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 15/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.56it/s]\n",
      "Fold 2, Epoch 15/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 15/20:\n",
      "  Train Loss: 7.8057\n",
      "  Val Loss: 11.9299\n",
      "  Val Disparity Error: 12.4218 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 16/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.51it/s]\n",
      "Fold 2, Epoch 16/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 16/20:\n",
      "  Train Loss: 7.7364\n",
      "  Val Loss: 11.6408\n",
      "  Val Disparity Error: 12.1322 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 17/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.57it/s]\n",
      "Fold 2, Epoch 17/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 17/20:\n",
      "  Train Loss: 8.3301\n",
      "  Val Loss: 10.7497\n",
      "  Val Disparity Error: 11.2405 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 18/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.47it/s]\n",
      "Fold 2, Epoch 18/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 18/20:\n",
      "  Train Loss: 9.8126\n",
      "  Val Loss: 11.8372\n",
      "  Val Disparity Error: 12.3314 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 19/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.59it/s]\n",
      "Fold 2, Epoch 19/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 19/20:\n",
      "  Train Loss: 9.5653\n",
      "  Val Loss: 10.0998\n",
      "  Val Disparity Error: 10.5938 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 20/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.57it/s]\n",
      "Fold 2, Epoch 20/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2, Epoch 20/20:\n",
      "  Train Loss: 8.1767\n",
      "  Val Loss: 8.5079\n",
      "  Val Disparity Error: 8.9984 pixels\n",
      "Fold 2 completed. Disparity Error: 8.9984 pixels\n",
      "Starting fold 3/5\n",
      "找到 24 个场景: ['artroom1', 'artroom2', 'bandsaw1', 'bandsaw2', 'chess1']...\n",
      "Fold 3: 训练场景数: 19, 验证场景数: 5\n",
      "训练数据集大小: 19, 验证数据集大小: 5\n",
      "场景 'artroom1' 校准信息:\n",
      "  原始尺寸: 1920x1080\n",
      "  最大视差: 170\n",
      "  视差范围: 55.0 - 142.0\n",
      "  基线长度: 536.62 mm\n",
      "使用最大视差值: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.49it/s]\n",
      "Fold 3, Epoch 1/20 (Validation): 100%|██████████| 5/5 [00:00<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 1/20:\n",
      "  Train Loss: 13.6145\n",
      "  Val Loss: 10.6354\n",
      "  Val Disparity Error: 11.1253 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 2/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.48it/s]\n",
      "Fold 3, Epoch 2/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 2/20:\n",
      "  Train Loss: 12.6367\n",
      "  Val Loss: 12.0758\n",
      "  Val Disparity Error: 12.5649 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 3/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.57it/s]\n",
      "Fold 3, Epoch 3/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 3/20:\n",
      "  Train Loss: 11.9760\n",
      "  Val Loss: 11.5280\n",
      "  Val Disparity Error: 12.0111 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 4/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.54it/s]\n",
      "Fold 3, Epoch 4/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 4/20:\n",
      "  Train Loss: 11.4449\n",
      "  Val Loss: 11.4112\n",
      "  Val Disparity Error: 11.8992 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 5/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.57it/s]\n",
      "Fold 3, Epoch 5/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 5/20:\n",
      "  Train Loss: 11.4773\n",
      "  Val Loss: 11.5006\n",
      "  Val Disparity Error: 11.9908 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 6/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.58it/s]\n",
      "Fold 3, Epoch 6/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 6/20:\n",
      "  Train Loss: 10.4805\n",
      "  Val Loss: 10.4551\n",
      "  Val Disparity Error: 10.9438 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 7/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.56it/s]\n",
      "Fold 3, Epoch 7/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 7/20:\n",
      "  Train Loss: 10.4113\n",
      "  Val Loss: 11.5417\n",
      "  Val Disparity Error: 12.0306 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 8/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.58it/s]\n",
      "Fold 3, Epoch 8/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 8/20:\n",
      "  Train Loss: 11.0760\n",
      "  Val Loss: 11.0896\n",
      "  Val Disparity Error: 11.5804 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 9/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.56it/s]\n",
      "Fold 3, Epoch 9/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 9/20:\n",
      "  Train Loss: 11.4397\n",
      "  Val Loss: 11.6211\n",
      "  Val Disparity Error: 12.1104 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 10/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.56it/s]\n",
      "Fold 3, Epoch 10/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 10/20:\n",
      "  Train Loss: 10.5679\n",
      "  Val Loss: 11.7699\n",
      "  Val Disparity Error: 12.2598 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 11/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.57it/s]\n",
      "Fold 3, Epoch 11/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 11/20:\n",
      "  Train Loss: 10.2389\n",
      "  Val Loss: 11.1005\n",
      "  Val Disparity Error: 11.5791 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 12/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.58it/s]\n",
      "Fold 3, Epoch 12/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 12/20:\n",
      "  Train Loss: 9.6505\n",
      "  Val Loss: 10.9305\n",
      "  Val Disparity Error: 11.4208 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 13/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.55it/s]\n",
      "Fold 3, Epoch 13/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 13/20:\n",
      "  Train Loss: 9.0464\n",
      "  Val Loss: 11.7128\n",
      "  Val Disparity Error: 12.1995 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 14/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.43it/s]\n",
      "Fold 3, Epoch 14/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 14/20:\n",
      "  Train Loss: 8.5891\n",
      "  Val Loss: 12.3688\n",
      "  Val Disparity Error: 12.8583 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 15/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.54it/s]\n",
      "Fold 3, Epoch 15/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 15/20:\n",
      "  Train Loss: 8.1888\n",
      "  Val Loss: 11.3684\n",
      "  Val Disparity Error: 11.8561 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 16/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.58it/s]\n",
      "Fold 3, Epoch 16/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 16/20:\n",
      "  Train Loss: 8.5957\n",
      "  Val Loss: 10.8964\n",
      "  Val Disparity Error: 11.3846 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 17/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.55it/s]\n",
      "Fold 3, Epoch 17/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 17/20:\n",
      "  Train Loss: 7.6389\n",
      "  Val Loss: 10.9535\n",
      "  Val Disparity Error: 11.4403 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 18/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.56it/s]\n",
      "Fold 3, Epoch 18/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 18/20:\n",
      "  Train Loss: 7.3604\n",
      "  Val Loss: 10.9296\n",
      "  Val Disparity Error: 11.4189 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 19/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.56it/s]\n",
      "Fold 3, Epoch 19/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 19/20:\n",
      "  Train Loss: 7.7295\n",
      "  Val Loss: 11.0286\n",
      "  Val Disparity Error: 11.5162 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 20/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.56it/s]\n",
      "Fold 3, Epoch 20/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3, Epoch 20/20:\n",
      "  Train Loss: 7.3503\n",
      "  Val Loss: 10.6773\n",
      "  Val Disparity Error: 11.1655 pixels\n",
      "Fold 3 completed. Disparity Error: 11.1655 pixels\n",
      "Starting fold 4/5\n",
      "找到 24 个场景: ['artroom1', 'artroom2', 'bandsaw1', 'bandsaw2', 'chess1']...\n",
      "Fold 4: 训练场景数: 19, 验证场景数: 5\n",
      "训练数据集大小: 19, 验证数据集大小: 5\n",
      "场景 'artroom1' 校准信息:\n",
      "  原始尺寸: 1920x1080\n",
      "  最大视差: 170\n",
      "  视差范围: 55.0 - 142.0\n",
      "  基线长度: 536.62 mm\n",
      "使用最大视差值: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.52it/s]\n",
      "Fold 4, Epoch 1/20 (Validation): 100%|██████████| 5/5 [00:00<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 1/20:\n",
      "  Train Loss: 15.7249\n",
      "  Val Loss: 20.9298\n",
      "  Val Disparity Error: 21.4210 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 2/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.54it/s]\n",
      "Fold 4, Epoch 2/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 2/20:\n",
      "  Train Loss: 10.7624\n",
      "  Val Loss: 19.8649\n",
      "  Val Disparity Error: 20.3532 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 3/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.51it/s]\n",
      "Fold 4, Epoch 3/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 3/20:\n",
      "  Train Loss: 9.9981\n",
      "  Val Loss: 19.1793\n",
      "  Val Disparity Error: 19.6661 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 4/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.44it/s]\n",
      "Fold 4, Epoch 4/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 4/20:\n",
      "  Train Loss: 9.2629\n",
      "  Val Loss: 17.0892\n",
      "  Val Disparity Error: 17.5811 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 5/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.46it/s]\n",
      "Fold 4, Epoch 5/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 5/20:\n",
      "  Train Loss: 8.6687\n",
      "  Val Loss: 18.2393\n",
      "  Val Disparity Error: 18.7286 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 6/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.43it/s]\n",
      "Fold 4, Epoch 6/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 6/20:\n",
      "  Train Loss: 9.3867\n",
      "  Val Loss: 17.1984\n",
      "  Val Disparity Error: 17.6921 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 7/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.45it/s]\n",
      "Fold 4, Epoch 7/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 7/20:\n",
      "  Train Loss: 8.5304\n",
      "  Val Loss: 18.1540\n",
      "  Val Disparity Error: 18.6441 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 8/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.44it/s]\n",
      "Fold 4, Epoch 8/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 8/20:\n",
      "  Train Loss: 9.6151\n",
      "  Val Loss: 17.6955\n",
      "  Val Disparity Error: 18.1880 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 9/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.43it/s]\n",
      "Fold 4, Epoch 9/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 9/20:\n",
      "  Train Loss: 9.1295\n",
      "  Val Loss: 18.6267\n",
      "  Val Disparity Error: 19.1212 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 10/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.57it/s]\n",
      "Fold 4, Epoch 10/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 10/20:\n",
      "  Train Loss: 8.8039\n",
      "  Val Loss: 19.1553\n",
      "  Val Disparity Error: 19.6460 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 11/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.54it/s]\n",
      "Fold 4, Epoch 11/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 11/20:\n",
      "  Train Loss: 8.7571\n",
      "  Val Loss: 18.4033\n",
      "  Val Disparity Error: 18.8955 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 12/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.55it/s]\n",
      "Fold 4, Epoch 12/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 12/20:\n",
      "  Train Loss: 8.1318\n",
      "  Val Loss: 18.2467\n",
      "  Val Disparity Error: 18.7381 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 13/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.56it/s]\n",
      "Fold 4, Epoch 13/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 13/20:\n",
      "  Train Loss: 7.7665\n",
      "  Val Loss: 18.1061\n",
      "  Val Disparity Error: 18.5989 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 14/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.54it/s]\n",
      "Fold 4, Epoch 14/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 14/20:\n",
      "  Train Loss: 7.7575\n",
      "  Val Loss: 16.1267\n",
      "  Val Disparity Error: 16.6173 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 15/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.51it/s]\n",
      "Fold 4, Epoch 15/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 15/20:\n",
      "  Train Loss: 7.1104\n",
      "  Val Loss: 17.9763\n",
      "  Val Disparity Error: 18.4658 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 16/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.57it/s]\n",
      "Fold 4, Epoch 16/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 16/20:\n",
      "  Train Loss: 7.0348\n",
      "  Val Loss: 17.9100\n",
      "  Val Disparity Error: 18.4044 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 17/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.57it/s]\n",
      "Fold 4, Epoch 17/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 17/20:\n",
      "  Train Loss: 6.9709\n",
      "  Val Loss: 17.4486\n",
      "  Val Disparity Error: 17.9394 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 18/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.55it/s]\n",
      "Fold 4, Epoch 18/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 18/20:\n",
      "  Train Loss: 7.4493\n",
      "  Val Loss: 17.5181\n",
      "  Val Disparity Error: 18.0100 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 19/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.51it/s]\n",
      "Fold 4, Epoch 19/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 19/20:\n",
      "  Train Loss: 6.5438\n",
      "  Val Loss: 15.5993\n",
      "  Val Disparity Error: 16.0924 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 20/20 (Training): 100%|██████████| 19/19 [00:03<00:00,  5.52it/s]\n",
      "Fold 4, Epoch 20/20 (Validation): 100%|██████████| 5/5 [00:00<00:00, 11.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4, Epoch 20/20:\n",
      "  Train Loss: 6.5582\n",
      "  Val Loss: 19.5694\n",
      "  Val Disparity Error: 20.0631 pixels\n",
      "Fold 4 completed. Disparity Error: 20.0631 pixels\n",
      "Starting fold 5/5\n",
      "找到 24 个场景: ['artroom1', 'artroom2', 'bandsaw1', 'bandsaw2', 'chess1']...\n",
      "Fold 5: 训练场景数: 20, 验证场景数: 4\n",
      "训练数据集大小: 20, 验证数据集大小: 4\n",
      "场景 'artroom1' 校准信息:\n",
      "  原始尺寸: 1920x1080\n",
      "  最大视差: 170\n",
      "  视差范围: 55.0 - 142.0\n",
      "  基线长度: 536.62 mm\n",
      "使用最大视差值: 170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.50it/s]\n",
      "Fold 5, Epoch 1/20 (Validation): 100%|██████████| 4/4 [00:00<00:00,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 1/20:\n",
      "  Train Loss: 16.9485\n",
      "  Val Loss: 9.5048\n",
      "  Val Disparity Error: 9.9871 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 2/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.45it/s]\n",
      "Fold 5, Epoch 2/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 2/20:\n",
      "  Train Loss: 12.8609\n",
      "  Val Loss: 12.1850\n",
      "  Val Disparity Error: 12.6714 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 3/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.51it/s]\n",
      "Fold 5, Epoch 3/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 3/20:\n",
      "  Train Loss: 13.0029\n",
      "  Val Loss: 10.9004\n",
      "  Val Disparity Error: 11.3943 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 4/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.47it/s]\n",
      "Fold 5, Epoch 4/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 4/20:\n",
      "  Train Loss: 12.3601\n",
      "  Val Loss: 9.6525\n",
      "  Val Disparity Error: 10.1450 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 5/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.48it/s]\n",
      "Fold 5, Epoch 5/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 5/20:\n",
      "  Train Loss: 12.2053\n",
      "  Val Loss: 9.6328\n",
      "  Val Disparity Error: 10.1224 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 6/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.53it/s]\n",
      "Fold 5, Epoch 6/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 6/20:\n",
      "  Train Loss: 11.5573\n",
      "  Val Loss: 9.3049\n",
      "  Val Disparity Error: 9.7957 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 7/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.51it/s]\n",
      "Fold 5, Epoch 7/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 7/20:\n",
      "  Train Loss: 12.3005\n",
      "  Val Loss: 13.5015\n",
      "  Val Disparity Error: 13.9962 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 8/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.50it/s]\n",
      "Fold 5, Epoch 8/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 8/20:\n",
      "  Train Loss: 12.2854\n",
      "  Val Loss: 8.8674\n",
      "  Val Disparity Error: 9.3615 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 9/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.49it/s]\n",
      "Fold 5, Epoch 9/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 9/20:\n",
      "  Train Loss: 11.4957\n",
      "  Val Loss: 8.7793\n",
      "  Val Disparity Error: 9.2732 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 10/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.49it/s]\n",
      "Fold 5, Epoch 10/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 10/20:\n",
      "  Train Loss: 11.5349\n",
      "  Val Loss: 9.4497\n",
      "  Val Disparity Error: 9.9442 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 11/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.51it/s]\n",
      "Fold 5, Epoch 11/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 11/20:\n",
      "  Train Loss: 11.5528\n",
      "  Val Loss: 8.6871\n",
      "  Val Disparity Error: 9.1812 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 12/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.48it/s]\n",
      "Fold 5, Epoch 12/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 12/20:\n",
      "  Train Loss: 10.7820\n",
      "  Val Loss: 9.7385\n",
      "  Val Disparity Error: 10.2313 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 13/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.51it/s]\n",
      "Fold 5, Epoch 13/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 13/20:\n",
      "  Train Loss: 10.2806\n",
      "  Val Loss: 8.5884\n",
      "  Val Disparity Error: 9.0818 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 14/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.49it/s]\n",
      "Fold 5, Epoch 14/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 14/20:\n",
      "  Train Loss: 10.7090\n",
      "  Val Loss: 10.0479\n",
      "  Val Disparity Error: 10.5444 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 15/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.50it/s]\n",
      "Fold 5, Epoch 15/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 15/20:\n",
      "  Train Loss: 10.8875\n",
      "  Val Loss: 9.2574\n",
      "  Val Disparity Error: 9.7508 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 16/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.48it/s]\n",
      "Fold 5, Epoch 16/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 16/20:\n",
      "  Train Loss: 9.7354\n",
      "  Val Loss: 9.4803\n",
      "  Val Disparity Error: 9.9739 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 17/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.50it/s]\n",
      "Fold 5, Epoch 17/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 17/20:\n",
      "  Train Loss: 9.5782\n",
      "  Val Loss: 8.5053\n",
      "  Val Disparity Error: 8.9965 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 18/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.42it/s]\n",
      "Fold 5, Epoch 18/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 18/20:\n",
      "  Train Loss: 9.6034\n",
      "  Val Loss: 13.1464\n",
      "  Val Disparity Error: 13.6432 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 19/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.44it/s]\n",
      "Fold 5, Epoch 19/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 19/20:\n",
      "  Train Loss: 9.3876\n",
      "  Val Loss: 8.6664\n",
      "  Val Disparity Error: 9.1615 pixels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 20/20 (Training): 100%|██████████| 20/20 [00:03<00:00,  5.48it/s]\n",
      "Fold 5, Epoch 20/20 (Validation): 100%|██████████| 4/4 [00:00<00:00, 10.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5, Epoch 20/20:\n",
      "  Train Loss: 8.5755\n",
      "  Val Loss: 12.0303\n",
      "  Val Disparity Error: 12.5215 pixels\n",
      "Fold 5 completed. Disparity Error: 12.5215 pixels\n",
      "Cross-validation completed. Results saved to ../results\n"
     ]
    }
   ],
   "source": [
    "# 参数\n",
    "k = 5  # 折数\n",
    "num_epochs = 20  # 训练轮数\n",
    "\n",
    "# 创建架构图\n",
    "create_architecture_diagram()\n",
    "\n",
    "# 测试读取校准文件\n",
    "scenes = [d for d in os.listdir(INPUT_DIR) if os.path.isdir(os.path.join(INPUT_DIR, d))]\n",
    "if scenes:\n",
    "    test_scene = scenes[0]\n",
    "    calib_file = os.path.join(INPUT_DIR, test_scene, 'calib.txt')\n",
    "    if os.path.exists(calib_file):\n",
    "        print(f\"\\n读取样本校准文件: {calib_file}\")\n",
    "        calib_params = read_calib_file(calib_file)\n",
    "        print(\"校准参数:\")\n",
    "        for key, value in calib_params.items():\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "run_cross_validation(INPUT_DIR, OUTPUT_DIR, k=k, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e4a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
